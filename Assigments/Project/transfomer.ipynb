{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wmt14 (/home/kydliceh/.cache/huggingface/datasets/wmt14/de-en/1.0.0/2de185b074515e97618524d69f5e27ee7545dcbed4aa9bc1a4235710ffca33f4)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.08990263938903809,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c43ceedee845079e6a035eea95e047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "wmt14 = load_dataset('wmt14', 'de-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_it = map(lambda x: x['de'] , wmt14['train'][:10000]['translation'])\n",
    "en_it = map(lambda x: x['en'] , wmt14['train'][:10000]['translation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.models import BPE\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "\n",
    "def create_tokenizer(iterable, add_special_tokens=False):\n",
    "    trainer = BpeTrainer(vocab_size=52_000, show_progress=True, special_tokens=[\"[UNK]\"])\n",
    "    tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "    tokenizer.pre_tokenizer = Whitespace()\n",
    "    if add_special_tokens:\n",
    "        tokenizer.add_special_tokens([\"[START]\", \"[END]\"])\n",
    "        tokenizer.post_processor = TemplateProcessing(single=\"[START] $A [END]\", special_tokens=[(\"[START]\", 52001), (\"[END]\", 52002)])\n",
    "    tokenizer.enable_padding()\n",
    "    tokenizer.train_from_iterator(iterable, trainer=trainer)\n",
    "    return tokenizer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "de_token = create_tokenizer(de_it, add_special_tokens=True)\n",
    "en_token = create_tokenizer(en_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt_subset = wmt14[\"train\"].train_test_split(0.99)[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embedding(embeds, lang):\n",
    "    return {f\"{lang}_ids\": [e.ids for e in embeds], f\"{lang}_att\": [e.attention_mask for e in embeds]}\n",
    "\n",
    "\n",
    "def tokenize(trans):\n",
    "    translation = trans[\"translation\"]\n",
    "    en = en_token.encode_batch([t[\"en\"] for t in translation])\n",
    "    de = de_token.encode_batch([t[\"de\"] for t in translation])\n",
    "    dct = {**extract_embedding(en, \"en\"), **extract_embedding(de, \"de\")}\n",
    "    return dct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.06682133674621582,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 4509,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f782b8fed14089b0a494cf28e3be93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4509 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wmt_tokenized = wmt_subset.map(tokenize, batch_size=10, batched=True)\n",
    "wmt_tokenized = wmt_tokenized.remove_columns(\"translation\")\n",
    "wmt_tokenized.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fc(batch):\n",
    "    en_ids = torch.stack([b[\"en_ids\"] for b in batch])\n",
    "    en_att = torch.stack([b[\"en_att\"] for b in batch]).unsqueeze(1).unsqueeze(1)\n",
    "    de_ids = torch.stack([b[\"de_ids\"] for b in batch])\n",
    "    de_att = torch.stack([b[\"de_att\"] for b in batch]).unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "    return {\"en_ids\": en_ids, \"de_ids\": de_ids, \"en_att\": en_att, \"de_att\": de_att}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(wmt_tokenized, batch_size=10, collate_fn=collate_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def create_report(\n",
    "    writer: SummaryWriter,\n",
    "    loss: float,\n",
    "    batch_i: int,\n",
    "    total_batches: int,\n",
    "    start_time: float,\n",
    "    epoch: int,\n",
    "):\n",
    "    index = batch_i + epoch * total_batches\n",
    "    tm = time.time() - start_time\n",
    "    writer.add_scalar(\"Loss/train\", loss, index)\n",
    "    writer.add_scalar(\"Time/train\", tm, index)\n",
    "    print(\n",
    "        \"Progress/train\", f\"{epoch}: {batch_i}/{total_batches} Loss: {loss}, Time: {tm}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scheduler: object,\n",
    "    criterion: nn.Module,\n",
    "    train_data: DataLoader,\n",
    "    writer: SummaryWriter,\n",
    "    epoch: int,\n",
    "    minibatch=False,\n",
    "):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    interval = 100\n",
    "    if minibatch:\n",
    "        train_data = [next(iter(train_data))]\n",
    "\n",
    "    total_batches = len(train_data) - 1\n",
    "    for batch_i, batch in enumerate(train_data):\n",
    "        # Remove last token from target as it is not required\n",
    "        target_ids = batch[\"de_ids\"][:, :-1]\n",
    "        target_att = batch[\"de_att\"][:, :, : ,:-1]\n",
    "        source_ids = batch[\"en_ids\"]\n",
    "        source_att = batch[\"en_att\"]\n",
    "\n",
    "\n",
    "        output = model(source_ids, target_ids, source_att, target_att\n",
    "        )\n",
    "\n",
    "        target_correct = batch[\"de_ids\"][:, 1:]\n",
    "        loss = criterion(output.transpose(1,2), target_correct)\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch_i % interval == 0 and batch_i > 0:\n",
    "            create_report(\n",
    "                writer, total_loss / interval, batch_i, total_batches, start_time, epoch\n",
    "            )\n",
    "            total_loss = 0\n",
    "            start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import WMTModel\n",
    "model = WMTModel(52003, 52003, 512)\n",
    "# Set to square root of model\n",
    "# Then multiply by  min(step_num^−0.5 , step_num * warmup_steps^−1.5)\n",
    "initial_lr = 512 ** -0.5\n",
    "warmup_steps = 4000\n",
    "multiplier_lambda = lambda step: min((step+1) ** -0.5, (step+1) * warmup_steps ** -1.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, multiplier_lambda)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "writer = SummaryWriter()\n",
    "train(model, optimizer, scheduler ,criterion, dataloader, writer, 0, minibatch=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47d1cf54bf9cf5fce4b000eacb105df7d7e5f1fe165267018e0a6855939e5736"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
